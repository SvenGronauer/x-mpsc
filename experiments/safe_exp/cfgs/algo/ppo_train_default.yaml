
name: ppo
config:
  # Model args
  hidden_dim: 64
  norm_obs: True
  norm_reward: False
  clip_obs: 100.
  clip_reward: 10.

  # Loss args
  gamma:  0.99
  use_gae:  True
  gae_lambda: 0.95
  use_clipped_value: False
  clip_param: 0.2
  target_kl: 0.01
  entropy_coef: 0.01

  # Optim args
  opt_epochs: 10
  mini_batch_size: 64
  actor_lr: 0.0003
  critic_lr: 0.001
  max_grad_norm: 0.5

  # Runner args
  max_env_steps: 30_000_000
  num_workers: 1
  rollout_batch_size: 1 #
  rollout_steps: 2000
  deque_size: 10
  eval_batch_size: 10

  # Misc
  log_interval: 1000
  save_interval: 1000
  num_checkpoints: 10
  eval_interval: 1000
  eval_save_best: True 
  tensorboard: True

  lr_schedule: linear